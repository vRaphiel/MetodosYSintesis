{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional GAN for MNIST\n",
        "\n",
        "A conditional GAN learns a separate “image manifold” for each class while still sharing parameters across classes. You tell the Generator which digit to generate (0–9) via a label y, and it maps (noise z, label y) to an image X that should look like a real MNIST digit of class y.\n",
        "\n",
        "Conceptually, each label carves the latent space into a family of submanifolds: change z to vary style within the class; change y to switch class.\n",
        "\n",
        "## Setup & Import\n",
        "- import torch + numpy + other libs needed\n",
        "- get current device"
      ],
      "metadata": {
        "id": "xKZ3JdCQdO3U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_82W28UXcguA"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data (MNIST, handwritten digits 0–9)\n",
        "\n",
        "Load MNIST dataset and create a dataloader. The dataloader should include a **preprocessing pipeline** for the images in the dataset that:\n",
        "\n",
        "- convert each MNIST image (which comes as a PIL image) into a PyTorch tensor, with pixel values scaled from [0, 255] to [0, 1] --> use toTensor()\n",
        "- rescale those values from [0, 1] to [-1, 1] (which is the range expected by the neural network) --> use Normalize((0.5,), (0.5,)). Formula: (x - mean) / std -> (x - 0.5) / 0.5.\n",
        "\n",
        "Data loader requires as well the **MNIST dataset** (dataset.MNIST). Parameters:\n",
        "- root=\"./data\" -> where to store the dataset locally.\n",
        "- train=True -> load the training split (60,000 images).\n",
        "- download=True -> automatically download the dataset if it’s not already in ./data.\n",
        "- transform=transform -> apply the preprocessing pipeline defined (tensor conversion + normalization).\n",
        "\n",
        "Now you can **wrap the dataset in a DataLoader**, which handles batching, shuffling, and loading data efficiently. Parameters:\n",
        "- trainset\n",
        "- batch_size\n",
        "- shuffle=True -> randomly shuffles the dataset each epoch (important so the model doesn’t see the data in the same order every time).\n",
        "- num_workers=2 -> uses 2 subprocesses to load data in parallel, speeding up data loading.\n",
        "- pin_memory=True -> allows faster data transfer to GPU if available.\n",
        "\n"
      ],
      "metadata": {
        "id": "g8SzBRsBds6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size =\n",
        "\n",
        "# create data processing pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),  # -> [-1, 1]\n",
        "])\n",
        "\n",
        "# load and store locally the dataset\n",
        "trainset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "print('Total images', len(trainset))\n",
        "\n",
        "# create the dataloader\n",
        "loader   = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "print('number of batches per epoch (total images ÷ batch size)', len(loader))"
      ],
      "metadata": {
        "id": "EDxBGPs_dwLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models (Generator e Discriminator with simple MLPs)\n",
        "\n",
        "Again let's take the simplest option (using MLPs for both generator and discriminator).\n",
        "\n",
        "### GENERATOR\n",
        "The Generator takes a random noise vector (latent code, size = 100) which is chained with a one hot vector representing the class as input and transforms it into an image shaped like the MNIST digit requested by the class (28×28 pixels, grayscale).\n",
        "\n",
        "#### How the input is formed\n",
        "\n",
        "Noise vector z provides randomness -> controls style variations of the generated digit (slant, thickness, stroke, etc.).\n",
        "\n",
        "Label y is converted to a one-hot vector of length 10 (digit “3” → [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]) -> tells the Generator which class of digit it should produce.\n",
        "\n",
        "Noise and label are joined along the feature dimension and passed to the first linear layer. The rest of phyolosophy for building the model is the same as seen before."
      ],
      "metadata": {
        "id": "6jBJ4wb0d49z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dimension of the latent space\n",
        "z_dim    = 100\n",
        "\n",
        "# number of classes to be controlled\n",
        "num_classes = 10\n",
        "\n",
        "# -----------------------\n",
        "# Conditional Generator\n",
        "# -----------------------\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    Input:  z ~ N(0,1) of shape [B, z_dim]\n",
        "            y_onehot of shape [B, num_classes]\n",
        "    Output: fake image in [-1, 1], shape [B, 1, 28, 28]\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim, num_classes):\n",
        "        super().__init__()\n",
        "        in_dim = z_dim + num_classes\n",
        "        self.net = nn.Sequential(\n",
        "            ...,\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, y_onehot):\n",
        "        x = torch.cat([z, y_onehot], dim=1)     # [B, z_dim + C]\n",
        "        x = self.net(x)                         # [B, 784]\n",
        "        return x.view(-1, 1, 28, 28)\n",
        "\n",
        "# -----------------------"
      ],
      "metadata": {
        "id": "FHPBTwOJd9Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DISCRIMINATOR\n",
        "The discriminator is  a binary classifier: given an image, it predicts how likely it is to be real (from MNIST) vs fake (from the Generator).\n",
        "\n",
        "As for the generator, the input image should be concatenated with the class label (flatten the image + concatenate the one-hot class vector).\n",
        "\n",
        "As before, we huse BCEWithLogits as loss, so let teh model oupt the logits"
      ],
      "metadata": {
        "id": "3TD83jeDlg1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# -----------------------\n",
        "# Conditional Discriminator\n",
        "# -----------------------\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Input:  x image in [-1,1], shape [B, 1, 28, 28]\n",
        "            y_onehot of shape [B, num_classes]\n",
        "    Output: logits, shape [B]\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        in_dim = 28*28 + num_classes\n",
        "        self.net = nn.Sequential(\n",
        "            # output -> logits\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y_onehot):\n",
        "        b = x.size(0)\n",
        "        # flatten images and concatenate with one hot labels\n",
        "        flat = x.view(b, -1)                    # [B, 784]\n",
        "        inp = torch.cat([flat, y_onehot], dim=1)# [B, 784 + C]\n",
        "        return self.net(inp).view(-1)           # [B]\n",
        "\n",
        "# create generator, discrimintaor and count their parameters\n",
        "G = Generator(z_dim, num_classes).to(device)\n",
        "D = Discriminator(num_classes).to(device)\n",
        "print('Generator parameters =', sum(p.numel() for p in G.parameters()),\n",
        "       '\\nDiscriminator parameters =', sum(p.numel() for p in D.parameters()))"
      ],
      "metadata": {
        "id": "W-pb76R0ljRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss, and optimizers (and utilities...)\n",
        "\n",
        "As loss, we use BCEWithLogitsLoss(), Adam as optimizers (use the same parameters as for unconditional generation), and again label smoothing.\n",
        "\n",
        "Finally, create a set of fixed latent codes to visualize generation progresses (10 columns of 8 digits).\n"
      ],
      "metadata": {
        "id": "-lMeAvFBsju-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we take the option of using BCEWithLogits as loss...\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# creating the optimizers\n",
        "optG = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "optD = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
        "\n",
        "real_label = 0.9   # label smoothing\n",
        "fake_label = 0.0\n",
        "\n",
        "# -----------------------\n",
        "# One-hot helper\n",
        "# -----------------------\n",
        "def to_onehot(y, num_classes, device):\n",
        "    # y: LongTensor of shape [B]\n",
        "    return F.one_hot(y, num_classes=num_classes).float().to(device)\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Fixed noise & labels for monitoring\n",
        "# (8 samples per class -> 80 total, or keep 64 if you prefer)\n",
        "# -----------------------\n",
        "torch.manual_seed(0)\n",
        "n_per_class = 8\n",
        "fixed_y = torch.arange(num_classes).repeat(n_per_class).to(device)  # 0..9, 0..9, ... (8 volte)\n",
        "fixed_y_onehot = to_onehot(fixed_y, num_classes, device)\n",
        "fixed_z = torch.randn(fixed_y.size(0), z_dim, device=device)\n",
        "\n",
        "# create an output directory to save generated images for later use...\n",
        "os.makedirs(\"samples\", exist_ok=True)\n",
        "\n",
        "def show_grid(tensor, title=None, nrow=10):\n",
        "    # nrow=10 to group by class nicely\n",
        "    imgs = (tensor.clamp(-1,1) + 1)/2\n",
        "    grid = utils.make_grid(imgs, nrow=nrow, padding=2, normalize=False)\n",
        "    npimg = grid.detach().cpu().numpy()\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.axis(\"off\")\n",
        "    if title: plt.title(title)\n",
        "    plt.imshow(np.transpose(npimg, (1,2,0)), cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u6Wei6IMsyuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop\n",
        "\n",
        "Training is a two-player game:\n",
        "- the Generator maps random noise and class label to fake MNIST images corresponding to the indicated label\n",
        "- the Discriminator receives an image and its label and outputs a score (logit) for real vs fake.\n",
        "\n",
        "At each iteration:\n",
        "- Update D, by using real images from dataloader + fake images from the generator (G is not updated in this step)\n",
        "- Update G, by using fake images only (D is not updated in this step)\n",
        "\n",
        "You repeat this over multiple epochs. As D improves at spotting fakes, G is pushed to produce more realistic digits; as G improves, D must refine its decision boundary.\n",
        "\n",
        "NOTE: take care that the number of batch images may be smaller than the batch size for the last batch... compute the real batch size at each iteration\n",
        "\n"
      ],
      "metadata": {
        "id": "q2vWd7sQwnhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs =\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    for i, (real, y) in enumerate(loader):   # <-- get labels from the dataloader\n",
        "        real = real.to(device)\n",
        "        y = y.to(device)\n",
        "        y_onehot = to_onehot(y, num_classes, device)\n",
        "        b = real.size(0)\n",
        "\n",
        "        # ======== Update D ========\n",
        "        # put D in training mode and clear its gradient\n",
        "\n",
        "\n",
        "        # 1. feed real images into D\n",
        "\n",
        "        # label smoothing... create a set of labels 0.9 instead of 1.0\n",
        "        # this discourages the discriminator from becoming overconfident\n",
        "        # remember that BCEWithLogits takes as input logits and not discrete labels\n",
        "\n",
        "        # 2. feed fake images into D (stop gradient through G)\n",
        "        # note: use torch.no_grad() or G.detach()\n",
        "\n",
        "        # 3. compute loss and backprop for D\n",
        "\n",
        "        # ======== Update G ========\n",
        "        # put G intraining mode and zero its gradient\n",
        "\n",
        "\n",
        "        # 1. feed fake images into D\n",
        "\n",
        "        # 2. compute loss and backprop for G\n",
        "\n",
        "        # ======== logging ========\n",
        "        # log each 200 steps and show progress\n",
        "        if (i % 200 == 0):\n",
        "            clear_output(wait=True)\n",
        "            print(f\"[{epoch:02d}/{epochs:02d}] step {i:04d} | loss_D={loss_D.item():.3f}  loss_G={loss_G.item():.3f}\")\n",
        "            with torch.no_grad():\n",
        "                G.eval()\n",
        "                preview = G(fixed_z, fixed_y_onehot)\n",
        "            show_grid(preview, title=f\"Epoch {epoch} | Step {i} (by class rows)\", nrow=num_classes)\n",
        "\n",
        "\n",
        "    # epoch end: save a grid on disk and show progress\n",
        "    with torch.no_grad():\n",
        "        G.eval()\n",
        "        preview = G(fixed_z, fixed_y_onehot)\n",
        "\n",
        "    # before saving images, denormalizes them in [0,1]\n",
        "    utils.save_image((preview+1)/2, f\"samples/epoch_{epoch:02d}_cgan.png\", nrow=num_classes)\n",
        "    clear_output(wait=True)\n",
        "    print(f\"Saved: samples/epoch_{epoch:02d}_cgan.png\")\n",
        "    show_grid(preview, title=f\"Epoch {epoch} (saved, conditional)\", nrow=num_classes)"
      ],
      "metadata": {
        "id": "xRgwEhvjwxyA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}